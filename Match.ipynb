{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install and update pyblp (only if necessary)\n",
    "# pip install pyblp\n",
    "# pip install --upgrade pyblp\n",
    "\n",
    "import pyblp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)  # print all columns of a dataframe; we can replace \"None\" by any number if we want to print a certain number of columns\n",
    "pd.set_option(\"max_colwidth\", None)   # Set the Column Width.\n",
    "pd.set_option(\"display.max_rows\", 100) \n",
    "np.set_printoptions(precision=3)\n",
    "pd.options.display.float_format\n",
    "pyblp.options.digits = 2\n",
    "pyblp.options.verbose = False\n",
    "pyblp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mac\n",
    "de = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/data/processed data/official fuel efficiency/2015_2023_fe_aggregate.csv\", low_memory=False) # aggregate emission data\n",
    "ds = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/data/processed data/sales/2015_2023_sales_aggregate.csv\", low_memory=False) # aggregate sales data\n",
    "df_size = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/Consumer demographics/number of household_uk_ge_fr.csv\")   # household number\n",
    "df_charging = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/charging infrastructure/Charging points_uk_fr_ge.csv\")   # charing devices \n",
    "df_gdp = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/Consumer demographics/gdp_pc.csv\")  # gdp/capita\n",
    "df_evstock = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/miscellaneous/EV_stock.csv\")   # EV stock\n",
    "# demographic data\n",
    "df_dm22 = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd22_eul_phhwta22.tab\",sep='\\t',low_memory=False)\n",
    "df_dm21 = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd21_eul_phhwta22.tab\",sep='\\t',low_memory=False)\n",
    "df_dm20 = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd20_eul_phhwta22.tab\",sep='\\t',low_memory=False)\n",
    "df_dm19 = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd19_eul.tab\",sep='\\t',low_memory=False)\n",
    "df_dm18 = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd18_eul.tab\",sep='\\t',low_memory=False)\n",
    "df_dm17 = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd17_eul.tab\",sep='\\t',low_memory=False)\n",
    "df_dm16 = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd16_eul.tab\",sep='\\t',low_memory=False)\n",
    "df_dm15 = pd.read_csv(\"/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd15_eul.tab\",sep='\\t',low_memory=False)\n",
    "df_dm22['market_ids'] = '2022'\n",
    "df_dm21['market_ids'] = '2021'\n",
    "df_dm20['market_ids'] = '2020'\n",
    "df_dm19['market_ids'] = '2019'\n",
    "df_dm18['market_ids'] = '2018'\n",
    "df_dm17['market_ids'] = '2017'\n",
    "df_dm16['market_ids'] = '2016'\n",
    "df_dm15['market_ids'] = '2015'\n",
    "\n",
    "\n",
    "### Windows\n",
    "#de = pd.read_csv('C:/Users/uctpql0/OneDrive - University College London/Cars data/data/processed data/official fuel efficiency/2015_2023_fe_aggregate.csv', low_memory=False)  # aggregate emission data\n",
    "#ds = pd.read_csv('C:/Users/uctpql0/OneDrive - University College London/Cars data/data/processed data/sales/2015_2023_sales_aggregate.csv', low_memory=False)  # aggregate sales data\n",
    "#df_size = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/Consumer demographics/number of household_uk_ge_fr.csv\") # household number\n",
    "#df_charging = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/charging infrastructure/Charging points_uk_fr_ge.csv\") # charing devices\n",
    "#df_gdp = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/Consumer demographics/gdp_pc.csv\") # gdp/capita\n",
    "#df_evstock = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/miscellaneous/EV_stock.csv\") # EV stock\n",
    "# demographic data\n",
    "#df_dm22 = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd22_eul_phhwta22.tab\",sep='\\t',low_memory=False)\n",
    "#df_dm21 = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd21_eul_phhwta22.tab\",sep='\\t',low_memory=False)\n",
    "#df_dm20 = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd20_eul_phhwta22.tab\",sep='\\t',low_memory=False)\n",
    "#df_dm19 = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd19_eul.tab\",sep='\\t',low_memory=False)\n",
    "#df_dm18 = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd18_eul.tab\",sep='\\t',low_memory=False)\n",
    "#df_dm17 = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd17_eul.tab\",sep='\\t',low_memory=False)\n",
    "#df_dm16 = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd16_eul.tab\",sep='\\t',low_memory=False)\n",
    "#df_dm15 = pd.read_csv(\"C:/Users/uctpql0/OneDrive - University College London/Cars data/Consumer demographics/UK/UK Annual Household Survey/tab files/apsh_jd15_eul.tab\",sep='\\t',low_memory=False)\n",
    "#df_dm22['market_ids'] = '2022'\n",
    "#df_dm21['market_ids'] = '2021'\n",
    "#df_dm20['market_ids'] = '2020'\n",
    "#df_dm19['market_ids'] = '2019'\n",
    "#df_dm18['market_ids'] = '2018'\n",
    "#df_dm17['market_ids'] = '2017'\n",
    "#df_dm16['market_ids'] = '2016'\n",
    "#df_dm15['market_ids'] = '2015'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#de['parent'].nunique() # 33\n",
    "#ds['parent'].nunique() # 43\n",
    "# show elements in ds['parent'].unique() but not in de['parent'].unique()\n",
    "#set(ds['parent'].unique()) - set(de['parent'].unique()) # {'Aiway','Alpina','Borgward','CHN Industrial','DFSK','MPM','Saab','Wanxiang','Wisemann','Xiamen Kinglong'}\n",
    "#de['brand'].nunique() # 74\n",
    "#ds['brand'].nunique() # 83\n",
    "# show elements in ds['brand'].unique() but not in de['brand'].unique()\n",
    "#set(ds['brand'].unique()) - set(de['brand'].unique()) # {'Bollore','Borgward','Corvette','Karma','MPM Motors','Saab','Seres','Ssangyong','Wiesmann'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merge sales and emission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### miscellaneous\n",
    "ds = ds.rename(columns={'body group': 'body type'})  # \n",
    "de['body type'] = de['body type'].str.lower()  # change column body type to lowercase\n",
    "\n",
    "### Merge the dataframes with matching columns: ['parent', 'brand', 'body type' and 'fuel type'] and matching values: ['nedc', 'wltp','range', 'capacity','mass', 'mass_wltp']\n",
    "df = ds.merge(\n",
    "    de[['parent', 'brand', 'body type', 'fuel type', 'nedc', 'wltp', 'range', 'capacity', 'mass', 'mass_wltp']],\n",
    "    on=['parent', 'brand', 'body type', 'fuel type'],\n",
    "    how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transform from short to long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_vars: ['country', 'parent', 'brand', 'body type', 'fuel type', 'power', 'horsepower', 'weight', 'price_local', 'price_eur', 'nedc', 'wltp', 'range', 'capacity', 'mass', 'mass_wltp'']\n",
    "# var_name: 'year'\n",
    "# value_name: 'sale'\n",
    "df = df.melt(id_vars=['country', 'parent', 'brand', 'body type', 'fuel type', 'power',\n",
    "       'horsepower', 'weight', 'price_local', 'price_eur', 'nedc', 'wltp', 'range', 'capacity', \n",
    "       'mass', 'mass_wltp'], value_vars=df.loc[:, '2015':'2023'].columns.tolist(), var_name='year', value_name='sale') \n",
    "df['year'] = df['year'].astype(int) # convert 'year' to integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################         Data cleaning           #############################################################   \n",
    "df = df[df['sale']>0]     # 1631064\n",
    "df = df[df['weight']>0]    #  1596899     # lost  34,165 sales \n",
    "\n",
    "### remove luxury cars\n",
    "# df['price_local'] = df['price_local'].astype(int)  \n",
    "df = df[df['price_eur']<200000]\n",
    "\n",
    "### remove missing values in weight, power, horsepower and fuel type.\n",
    "df = df.dropna(subset=['weight', 'power', 'horsepower'])    # no missing values in 'weight', 'power', 'horsepower'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. add market size and charging device data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### clean the household number data\n",
    "df_size_cp = df_size.iloc[:3,:].copy()   # keep only the first 3 rows of the dataframe\n",
    "df_size_cp = df_size_cp.melt(id_vars=['country'], value_vars = df_size_cp.columns[1:], var_name='year', value_name='market size')    # transform the df_size to the long format\n",
    "\n",
    "### match the market size with the 'country' and 'year'\n",
    "df['year'] = df['year'].astype(str)   # convert 'year' to 'str' type temporarily\n",
    "df['market size'] = df.apply(lambda row: df_size_cp[(df_size_cp['country'] == row['country']) & (df_size_cp['year'] == row['year'])]['market size'].values[0] \n",
    "                             if not df_size_cp[(df_size_cp['country'] == row['country']) & (df_size_cp['year'] == row['year'])]['market size'].empty else None, axis=1)  # promt: add a column 'market size' to df_long, whose values such that the values of 'market size' match the values in dataframe df_size according to the 'country' and 'year'\n",
    "df['market size'] = df['market size'].str.replace(',' , '').astype(float)    # change the data type of 'market size' from object to float\n",
    "df['year'] = df['year'].astype(int)   #convert 'year' back to 'int' type\n",
    "\n",
    "### add charing devices data\n",
    "# transform df_charge from long to wide format\n",
    "df_charging_cp = df_charging.pivot(index=['country','year'], columns='charging_type', values='value').reset_index().copy()\n",
    "df['s_charge'] = df.apply(lambda row: df_charging_cp[(df_charging_cp['year'] == row['year'])]['s_charge'].values[0] \n",
    "                          if not df_charging_cp[(df_charging_cp['year'] == row['year'])]['s_charge'].empty else None, axis=1) \n",
    "df['f_charge'] = df.apply(lambda row: df_charging_cp[(df_charging_cp['year'] == row['year'])]['f_charge'].values[0] \n",
    "                          if not df_charging_cp[(df_charging_cp['year'] == row['year'])]['f_charge'].empty else None, axis=1) \n",
    "\n",
    "### add gdp/capita data\n",
    "#df_gdp.drop(columns = [\"Unnamed: 4\", \"Unnamed: 5\", \"Unnamed: 6\", \"Unnamed: 7\", \"Unnamed: 8\"], inplace = True)\n",
    "df['gdp_pc'] = df.apply(lambda row: df_gdp[(df_gdp['country'] == row['country']) & (df_gdp['year'] == row['year'])]['gdp_pc_dollar'].values[0] \n",
    "                        if not df_gdp[(df_gdp['country'] == row['country']) & (df_gdp['year'] == row['year'])]['gdp_pc_dollar'].empty else None, axis=1)\n",
    "\n",
    "### add EV stock data\n",
    "df_evstock = df_evstock[df_evstock['region'].isin(['United Kingdom','France','Germany'])]\n",
    "df_evstock = df_evstock[df_evstock['parameter']=='EV stock']\n",
    "df_evstock.drop(columns=['category', 'parameter' ,'mode', 'unit'],inplace=True)\n",
    "df_evstock = df_evstock[df_evstock['powertrain']!='FCEV']\n",
    "df_evstock_group = df_evstock.groupby(['region','year']).agg({'value':'sum'}).reset_index()\n",
    "df_evstock_group.rename(columns={'value':'ev_stock'}, inplace=True)\n",
    "df['ev_stock'] = df.apply(lambda row: df_evstock_group[(df_evstock_group['region'] == row['country']) & (df_evstock_group['year'] == row['year'])]['ev_stock'].values[0] \n",
    "                          if not df_evstock_group[(df_evstock_group['region'] == row['country']) & (df_evstock_group['year'] == row['year'])]['ev_stock'].empty else None, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct subsidies prices\n",
    "df_l['subsidies'] = 0\n",
    "\n",
    "### UK (plug-in grant for BEV and PHEV)\n",
    "#\t2015-2018: 4500 for bev and 2500 for phev, with price below £60,000\n",
    "#\t2019-2020: 3000 for bev or phev, with price below £ 50,000\n",
    "#\t2021:      2500 for bev or phev, with price below £35,000\n",
    "#\t2022-2023: 1500 for bev only, price below 32,000\n",
    "\n",
    "df_l.loc[(df_l['country']=='United Kingdom') & \n",
    "         (df_l['year'].isin([2015, 2016, 2017, 2018])) & \n",
    "         (df_l['ft'] == 'bev') &\n",
    "         (df_l['price_local'] < 60000), 'subsidies'] = 4500\n",
    "\n",
    "df_l.loc[(df_l['country']=='United Kingdom') & \n",
    "         (df_l['year'].isin([2015, 2016, 2017, 2018])) & \n",
    "         (df_l['ft'] == 'phev') &\n",
    "         (df_l['price_local'] < 60000), 'subsidies'] = 4500\n",
    "\n",
    "df_l.loc[(df_l['country']=='United Kingdom') & \n",
    "\t\t (df_l['year'].isin([2019, 2020])) & \n",
    "\t\t (df_l['ft'].isin(['bev','phev'])) &\n",
    "\t\t (df_l['price_local']<50000), 'subsidies'] = 3000\n",
    "\n",
    "df_l.loc[(df_l['country']=='United Kingdom') & \n",
    "\t\t (df_l['year'].isin([2021])) & \n",
    "\t\t (df_l['ft'].isin(['bev','phev'])) &\n",
    "\t\t (df_l['price_local']<35000), 'subsidies'] = 2500\n",
    "\n",
    "df_l.loc[(df_l['country']=='United Kingdom') & \n",
    "\t\t (df_l['year'].isin([2022,2023])) & \n",
    "\t\t (df_l['ft'].isin(['bev'])) &\n",
    "\t\t (df_l['price_local']<32000), 'subsidies'] = 1500\n",
    "\n",
    "\n",
    "### Adding subsidies for France (bonus écologique for BEV and PHEV)\n",
    "#\t2015-2016:\t6300 for BEV, 1000 for PHEV \n",
    "#\t2017-2019: \t6000 for BEV, 1000 for PHEV \t\n",
    "#    2020: 6000 for BEV with price <45,000; 3000 for BEV with price 45,000-60,000; 500 for PHEV with emission of 20-60, price 45,000-60,000.\n",
    "#\t2021: 5000 for BEV with price <45,000; 3000 for BEV with price 45,000-60,000; 500 for PHEV with emission of 20-60, price 45,000-60,000.\n",
    "#\t2022-2023: 4000 for BEV with price <45,000; 3000 for BEV with price 45,000-60,000;\t500 for PHEV with emission of 20-60, price 45,000-60,000\n",
    "\n",
    "df_l.loc[(df_l['country']=='France') &\n",
    "\t\t (df_l['year'].isin([2015,2016])) &\n",
    "\t\t (df_l['ft'].isin(['bev'])),'subsidies'] = 6300\n",
    "\n",
    "df_l.loc[(df_l['country']=='France') &\n",
    "\t\t (df_l['year'].isin([2017,2018,2019])) &\n",
    "\t\t (df_l['ft'].isin(['bev'])),'subsidies'] = 6000\n",
    "\n",
    "df_l.loc[(df_l['country']=='France') &\n",
    "\t\t (df_l['year'].isin([2015,2016,2017,2018,2019])) &\n",
    "\t\t (df_l['ft'].isin(['phev'])),'subsidies'] = 1000\n",
    "\n",
    "\n",
    "\n",
    "df_l.loc[(df_l['country']=='France') &\n",
    "\t\t (df_l['year'].isin([2020])) &\n",
    "\t\t (df_l['ft'].isin(['bev'])) &\n",
    "\t\t (df_l['price_local']<45000),'subsidies'] = 6000\n",
    "\n",
    "df_l.loc[(df_l['country']=='France') &\n",
    "\t\t (df_l['year'].isin([2021])) &\n",
    "\t\t (df_l['ft'].isin(['bev'])) &\n",
    "\t\t (df_l['price_local']<45000),'subsidies'] = 5000\n",
    "\n",
    "df_l.loc[(df_l['country']=='France') &\n",
    "\t\t (df_l['year'].isin([2022,2023])) &\n",
    "\t\t (df_l['ft'].isin(['bev'])) &\n",
    "\t\t (df_l['price_local']<45000),'subsidies'] = 4000\n",
    "\n",
    "\n",
    "df_l.loc[(df_l['country']=='France') &\n",
    "\t\t (df_l['year'].isin([2020,2021,2022,2023])) &\n",
    "\t\t (df_l['ft'].isin(['bev'])) &\n",
    "\t\t (df_l['price_local']> 45000) &\n",
    "\t\t (df_l['price_local'] <= 60000),'subsidies'] = 3000\n",
    "\n",
    "df_l.loc[(df_l['country']=='France') &\n",
    "\t\t (df_l['year'].isin([2020,2021,2022,2023])) &\n",
    "\t\t (df_l['ft'].isin(['phev'])) &\n",
    "\t\t (df_l['price_local']> 45000) &\n",
    "\t\t (df_l['price_local'] <= 60000),'subsidies'] = 500\n",
    "\n",
    "\n",
    "### Adding subsidies for Germany (Umweltbonus for BEV and PHEV)\n",
    "#\t2015: 0\n",
    "#\t2016-2018: 4000 for BEV with price <40,000; 3000 for PHEV with price <65,000;\n",
    "#    2019: 6000 for BEV with price <40,000; 5000 for BEV with price 40,000-60,000; 4500 for PHEV with price <65,000;\n",
    "#\t2020-2023: 9000 for BEV with price <40,000; 6750 for PHEVs with price <65,000;\n",
    "\t\n",
    "df_l.loc[(df_l['country']=='Germany') &\n",
    "\t\t (df_l['year'].isin([2016,2017,2018])) &\n",
    "\t\t (df_l['ft'].isin(['bev'])) &\n",
    "\t\t (df_l['price_local']<40000),'subsidies'] = 4000\n",
    "\n",
    "df_l.loc[(df_l['country']=='Germany') &\n",
    "\t\t (df_l['year'].isin([2016,2017,2018])) &\n",
    "\t\t (df_l['ft'].isin(['phev'])) &\n",
    "\t\t (df_l['price_local']<65000),'subsidies'] = 3000\n",
    "\n",
    "\n",
    "\n",
    "df_l.loc[(df_l['country']=='Germany') &\n",
    "\t\t (df_l['year'].isin([2019])) &\n",
    "\t\t (df_l['ft'].isin(['bev'])) &\n",
    "\t\t (df_l['price_local']<40000),'subsidies'] = 6000\n",
    "\n",
    "df_l.loc[(df_l['country']=='Germany') &\n",
    "\t\t (df_l['year'].isin([2019])) &\n",
    "\t\t (df_l['ft'].isin(['bev'])) &\n",
    "\t\t (df_l['price_local']>40000) &\n",
    "\t\t (df_l['price_local']<60000),'subsidies'] = 5000\n",
    "\n",
    "df_l.loc[(df_l['country']=='Germany') &\n",
    "\t\t (df_l['year'].isin([2019])) &\n",
    "\t\t (df_l['ft'].isin(['phev'])) &\n",
    "\t\t (df_l['price_local']<65000),'subsidies'] = 4500\n",
    "\n",
    "\n",
    "\n",
    "df_l.loc[(df_l['country']=='Germany') &\n",
    "\t\t (df_l['year'].isin([2020,2021,2022,2023])) &\n",
    "\t\t (df_l['ft'].isin(['bev'])) &\n",
    "\t\t (df_l['price_local']<40000),'subsidies'] = 9000\n",
    "\n",
    "df_l.loc[(df_l['country']=='Germany') &\n",
    "\t\t (df_l['year'].isin([2020,2021,2022,2023])) &\n",
    "\t\t (df_l['ft'].isin(['phev'])) &\n",
    "\t\t (df_l['price_local']>40000) &\n",
    "\t\t (df_l['price_local']<60000),'subsidies'] = 6750\n",
    "\n",
    "\n",
    "\n",
    "###### create column for subsidied price and unsubsidied price\n",
    "\n",
    "df_l['price_local_sub'] = df_l['price_local'] - df_l['subsidies']\n",
    "\n",
    "df_l['price_sub'] = df_l['price_local_sub'] * df_l['ex_rate']\n",
    "\n",
    "df_l['price_unsub'] = df_l['price_eur']\n",
    "\n",
    "############################# match the values in 'df_rate' wiht 'exchange rate' in 'df_l' with 'pound_to_euro' in 'df_rate' according to 'year' in both dataframes #####################################\n",
    "#df_l['exchange rate'] = df_l.apply(lambda row: df_rate[(df_rate['year'] == row['year'])]['pound_to_euro'].values[0] if not df_rate[(df_rate['year'] == row['year'])]['pound_to_euro'].empty else None, axis=1)\n",
    "#df_l['price(£)'] = df_l['price'] / df_l['exchange rate']\n",
    "#df_l['prices'] = df_l['price(£)'] - df_l['subsidies']   # subtract 'subsidies' from 'price'\n",
    "#########################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. generate demand instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare for running pyblp\n",
    "df['year'] = df['year'].astype(str)   # convert 'year' to string type\n",
    "df['market_ids'] = df['country'] + '_' + df['year']   # create a 'market_id' column equal to 'year'\n",
    "# generate a 'product_id' for each combination of 'parent', 'brand', 'body type' and 'fuel type'\n",
    "df['product_id'] = df['parent'] + '_' + df['brand'] + '_' + df['body type'] + '_' + df['fuel type']\n",
    "# convert 'product_id' to 'category' type and then to 'codes'\n",
    "df['product_id'] = df['product_id'].astype('category').cat.codes\n",
    "# rename the column name 'firm' to 'firm_ids'\n",
    "df = df.rename(columns={'parent': 'firm_ids'})   \n",
    "\n",
    "### Generate indicators variables for the categorical variables.\n",
    "df_dummies = pd.get_dummies(df['fuel type'], columns=['fuel type'], drop_first=False)   # One-hot encode 'ft'\n",
    "df_dummies = df_dummies.astype(int)    # Convert the encoded columns to integer type\n",
    "df = pd.concat([df, df_dummies], axis=1)      # Concatenate the original dataframe with the encoded columns\n",
    "\n",
    "\n",
    "## create columns 'demand_instruments0', 'demand_instruments1', and so on.\n",
    "demand_instruments = pyblp.build_blp_instruments(pyblp.Formulation( '1  + horsepower + weight + hybrid + phev + bev'), df)   # don't add 'ft' to the formula since it is categorical variable.\n",
    "demand_instruments_df = pd.DataFrame(demand_instruments)\n",
    "demand_instruments_df.columns = [f'demand_instruments{i}' for i in range(demand_instruments_df.shape[1])]  # rename the columns as 'demand_instruments0', 'demand_instruments1', and so on.\n",
    "\n",
    "## combine the demand_instruments_df and df\n",
    "# Reset index of both dataframes to ensure they align properly\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "demand_instruments_df.reset_index(drop=True, inplace=True)\n",
    "# Now concatenate\n",
    "df_combined = pd.concat([df, demand_instruments_df], axis=1)\n",
    "\n",
    "### convert data type of 'year' and 'market_ids' to integer\n",
    "df_combined['year'] = df_combined['year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. add demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2022, selected is 4426, total is 223196. representation is 1.98%\n",
      "In 2021, selected is 58658, total is 249997. representation is 23.46%\n",
      "In 2020, selected is 60815, total is 268289. representation is 22.67%\n",
      "In 2019, selected is 78325, total is 323754. representation is 24.19%\n",
      "In 2018, selected is 82168, total is 330859. representation is 24.83%\n",
      "In 2017, selected is 84287, total is 334195. representation is 25.22%\n",
      "In 2016, selected is 82399, total is 341049. representation is 24.16%\n",
      "In 2015, selected is 90423, total is 357037. representation is 25.33%\n"
     ]
    }
   ],
   "source": [
    "### create copies of the demographic data\n",
    "df_dm22_cp = df_dm22.copy() \n",
    "df_dm21_cp = df_dm21.copy() \n",
    "df_dm20_cp = df_dm20.copy() \n",
    "df_dm19_cp = df_dm19.copy()\n",
    "df_dm18_cp = df_dm18.copy()\n",
    "df_dm17_cp = df_dm17.copy()\n",
    "df_dm16_cp = df_dm16.copy()\n",
    "df_dm15_cp = df_dm15.copy()\n",
    "list_cp = [df_dm22_cp, df_dm21_cp, df_dm20_cp, df_dm19_cp, df_dm18_cp, df_dm17_cp, df_dm16_cp, df_dm15_cp]\n",
    "\n",
    "### Select sample based on response to qualification obtained and net weekly pay\n",
    "## show the selcted sample size for each year\n",
    "for df_dm in list_cp:           # add [df_dm14, df_dm13, df_dm12, df_dm11] if there are EV charging point data for these years\n",
    "    df_dm['year'] = df_dm['market_ids'].astype(int)\n",
    "    nb = df_dm[(df_dm['QUAL_1'] != -9.00) & (~df_dm['NETWK'].isin([-8, -9, -10]))].shape[0]     # selected sample size\n",
    "    nb_t = df_dm.shape[0]                                                                 # total sample size\n",
    "    pc = nb / nb_t                                                                     # proportion of selected sample\n",
    "    year = df_dm['market_ids'].unique()[0]     # to extract the year 'string' for printing\n",
    "    print(f'In {year}, selected is {nb}, total is {nb_t}. representation is {round(pc * 100, 2)}%')\n",
    "    df_dm.drop(df_dm[(df_dm['QUAL_1'] == -9.00) | (df_dm['NETWK'].isin([-8, -9, -10]))].index, inplace=True) # remove the observations where 'QUAL_1' is -9.00 or 'NETWK' is -8, -9, -10\n",
    "    df_dm['weights'] = 1/nb   # create a 'weights' column equal to 1/sample size\n",
    "    df_dm.rename(columns={'NETWK': 'income', 'AGE': 'age', 'QUAL_1': 'degree'}, inplace=True)  # rename the columns 'NETWK' as 'income', 'AGE' as 'age', 'QUAL_1' as 'degree'\n",
    "\n",
    "\n",
    "### Combine the demographics data vertically\n",
    "df_agent = pd.concat(list_cp, axis=0)\n",
    "\n",
    "\n",
    "### Generate Monte Carlo nodes\n",
    "# create the initial mc_stack\n",
    "integration = pyblp.Integration('monte_carlo', size = df_agent[df_agent['year']== 2015]['market_ids'].shape[0])\n",
    "mc = pyblp.build_integration(integration, 5)\n",
    "mc_array = mc['nodes']\n",
    "mc_stack = pd.DataFrame(mc_array, columns=['nodes0', 'nodes1', 'nodes2', 'nodes3', 'nodes4'])\n",
    "mc_stack = mc_stack.iloc[0:1]\n",
    "# stack the mc dataframes\n",
    "for i in range(2015,2023):       \n",
    "    integration = pyblp.Integration('monte_carlo', size = df_agent[df_agent['year']== i]['market_ids'].shape[0])\n",
    "    mc = pyblp.build_integration(integration, 5)\n",
    "    mc = mc['nodes']\n",
    "    mc = pd.DataFrame(mc, columns=['nodes0', 'nodes1', 'nodes2', 'nodes3', 'nodes4'])\n",
    "    mc_stack = pd.concat([mc_stack, mc], axis=0)    \n",
    "# remove the first row of 'mc_stack'\n",
    "mc_stack = mc_stack.iloc[1:]  \n",
    "# concatenate 'df_agent' and 'mc_stack' horizontally without matching the index\n",
    "df_agent = pd.concat([df_agent.reset_index(drop=True), mc_stack.reset_index(drop=True)], axis=1) \n",
    "\n",
    "\n",
    "### randomly select 100 rows of the df_agent for each unique 'market_ids'\n",
    "df_agent = df_agent.groupby('market_ids').apply(lambda x: x.sample(100)).reset_index(drop=True)\n",
    "df_agent['weights'] = 1/100 \n",
    "\n",
    "\n",
    "# convert data type of 'year' and 'market_ids' to integer\n",
    "df_agent['year'] = df_agent['year'].astype(int)\n",
    "df_agent['market_ids'] = df_agent['market_ids'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. estimation\n",
    "\n",
    "### Standardization\n",
    "product_data = df_combined.copy()\n",
    "# time\n",
    "product_data = product_data[(product_data['year']>=2015) & (product_data['year']<=2022)]    \n",
    "# rename column 'price_eur'\n",
    "product_data['prices'] = product_data['price_eur']\n",
    "# impactful models\n",
    "#product_data = product_data[product_data['sales']>1000]        \n",
    "# scale\n",
    "product_data['prices'] = product_data['prices'] / 1000  \n",
    "product_data['weight'] = product_data['weight'] / 1000\n",
    "product_data['horsepower'] = product_data['horsepower'] / 100  \n",
    "product_data['s_charge'] = product_data['s_charge'] / product_data['ev_stock']\n",
    "product_data['f_charge'] = product_data['f_charge'] / product_data['ev_stock']\n",
    "# market size determination\n",
    "market_size_discount = 1\n",
    "product_data['shares'] = product_data['sale'] / (product_data['market size']*1000*market_size_discount)\n",
    "\n",
    "# add 'clutering_ids' column\n",
    "product_data['clustering_ids'] = product_data['brand']\n",
    "\n",
    "# add dummy variables for 'year'\n",
    "pd_dummies = pd.get_dummies(product_data['year'], columns=['year'], drop_first=False)\n",
    "pd_dummies = pd_dummies.astype(int)\n",
    "product_data = pd.concat([product_data, pd_dummies], axis=1)\n",
    "\n",
    "#Interaction between fuel type and year\n",
    "product_data['phev_2015'] = product_data['phev']*product_data[2015]\n",
    "product_data['phev_2016'] = product_data['phev']*product_data[2016]\n",
    "product_data['phev_2017'] = product_data['phev']*product_data[2017]\n",
    "product_data['phev_2018'] = product_data['phev']*product_data[2018]\n",
    "product_data['phev_2019'] = product_data['phev']*product_data[2019]\n",
    "product_data['phev_2020'] = product_data['phev']*product_data[2020]\n",
    "product_data['phev_2021'] = product_data['phev']*product_data[2021]\n",
    "product_data['phev_2022'] = product_data['phev']*product_data[2022]\n",
    "#product_data['phev_2023'] = product_data['phev']*product_data[2023]\n",
    "\n",
    "product_data['bev_2015'] = product_data['bev']*product_data[2015]\n",
    "product_data['bev_2016'] = product_data['bev']*product_data[2016]\n",
    "product_data['bev_2017'] = product_data['bev']*product_data[2017]\n",
    "product_data['bev_2018'] = product_data['bev']*product_data[2018]\n",
    "product_data['bev_2019'] = product_data['bev']*product_data[2019]\n",
    "product_data['bev_2020'] = product_data['bev']*product_data[2020]\n",
    "product_data['bev_2021'] = product_data['bev']*product_data[2021]\n",
    "product_data['bev_2022'] = product_data['bev']*product_data[2022]\n",
    "#product_data['bev_2023'] = product_data['bev']*product_data[2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Logit (using instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_formulation = pyblp.Formulation('1 + prices + weight + horsepower + phev + bev + phev:s_charge + bev:s_charge ', absorb='C(model)')  # with fixed effects\n",
    "logit_formulation = pyblp.Formulation('1 + prices + weight + horsepower + nedc + range + phev + bev + phev:s_charge + bev:s_charge + phev_2016 + phev_2017 + phev_2018 + phev_2019 + phev_2020 + phev_2021 + phev_2022 + bev_2016 + bev_2017 + bev_2018 + bev_2019 + bev_2020 + bev_2021 + bev_2022', absorb='C(brand)')\n",
    "### Problem\n",
    "problem = pyblp.Problem(logit_formulation, product_data)\n",
    "logit_results = problem.solve()\n",
    "logit_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blp with no demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### No demographics BLP\n",
    "X1_formulation = pyblp.Formulation('1 + prices + weight + horsepower + phev + bev + phev:s_charge + bev:s_charge + phev_2016 + phev_2017 + phev_2018 + phev_2019 + phev_2020 + phev_2021 + phev_2022 + phev_2023 + bev_2016 + bev_2017 + bev_2018 + bev_2019 + bev_2020 + bev_2021 + bev_2022 + bev_2023', absorb='C(model)')  # with fixed effects\n",
    "X2_formulation = pyblp.Formulation('1 + prices + weight + horsepower + phev + bev')\n",
    "product_formulations = (X1_formulation, X2_formulation)\n",
    "### Initial parameters\n",
    "initial_sigma = np.diag([0.1,0.1,0.1,0.1,0.1,0.1])\n",
    "### Bounds for parameters\n",
    "bounds = (\n",
    "    [[0,0,0,0,0,0],       # lower bounds\n",
    "    [0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0]],   \n",
    "    \n",
    "    [[None,0,0,0,0,0],     # upper bounds\n",
    "    [0,None,0,0,0,0],\n",
    "    [0,0,None,0,0,0],\n",
    "    [0,0,0,None,0,0],\n",
    "    [0,0,0,0,None,0],\n",
    "    [0,0,0,0,0,None]], \n",
    "    )\n",
    "nd_problem = pyblp.Problem(product_formulations, \n",
    "                           product_data,  \n",
    "                           integration = pyblp.Integration('monte_carlo', size=100, specification_options={'seed':0}))\n",
    "nd_results = nd_problem.solve(initial_sigma,\n",
    "                              sigma_bounds=bounds,\n",
    "                              optimization=pyblp.Optimization('l-bfgs-b', {'gtol': 1e-5}),  \n",
    "                              iteration=pyblp.Iteration('squarem', {'atol': 1e-14}),\n",
    "                              )    # W_type='clustered', se_type='clustered'\n",
    "nd_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blp with demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data\n",
    "agent_data = df_agent[(df_agent['year']>=2015)&(df_agent['year']<=2021)].copy()\n",
    "product_data = df_combined[(df_combined['year']>=2015) & (df_combined['year']<=2021)].copy()\n",
    "product_data['prices'] = product_data['price_sub']\n",
    "#product_data['prices'] = product_data['price_unsub']\n",
    "\n",
    "market_size_discount = 1\n",
    "product_data['shares'] = product_data['sales'] / (product_data['market size']*1000*market_size_discount)\n",
    "#product_data = product_data.drop(columns=['demand_instruments3', 'demand_instruments4','demand_instruments8','demand_instruments9'])  # drop some instruments\n",
    "\n",
    "### With demographics BLP\n",
    "X1_formulation = pyblp.Formulation('1 + prices + weight + horsepower  + phev + bev + phev:s_charge + bev:s_charge', absorb='C(model)')  \n",
    "X2_formulation = pyblp.Formulation('1 + prices + horsepower + bev + phev')\n",
    "product_formulations = (X1_formulation, X2_formulation)\n",
    "agent_formulation = pyblp.Formulation('0 + income + degree')\n",
    "### Optimization method\n",
    "opt = pyblp.Optimization('l-bfgs-b', {'gtol':1e-4})\n",
    "### Initial parameters\n",
    "initial_sigma = np.diag([1,1,1,0,0])\n",
    "initial_pi = np.array([\n",
    "    [0, 0],\n",
    "    [1, 0],\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    ])\n",
    "### Bounds for parameters\n",
    "bounds = (\n",
    "    [[0.1,0,0,0,0],       # lower bounds\n",
    "    [0,0.1,0,0,0],\n",
    "    [0,0,0.1,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0]],   \n",
    "\n",
    "    [[10,0,0,0,0],     # upper bounds\n",
    "    [0,10,0,0,0],\n",
    "    [0,0,10,0,0],\n",
    "    [0,0,0,10,0],\n",
    "    [0,0,0,0,10]], \n",
    "    )\n",
    "\n",
    "wd_problem = pyblp.Problem(product_formulations, product_data, agent_formulation, agent_data)\n",
    "wd_results = wd_problem.solve(initial_sigma, initial_pi, optimization=opt, sigma_bounds = bounds)   # restrict the random coefficientmatrix to be diagonal\n",
    "wd_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
