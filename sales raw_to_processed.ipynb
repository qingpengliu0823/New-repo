{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(pd.__version__)\n",
    "print(pd.options.display.max_rows)\n",
    "pd.set_option(\"display.max_columns\", None)  # print all columns of a dataframe; we can replace \"None\" by any number if we want to print a certain number of columns\n",
    "pd.set_option(\"max_colwidth\", None)   # Set the Column Width.\n",
    "pd.set_option(\"display.max_rows\", 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################  Size of the Original Sales files  ################# \n",
    "# Total: 830400 rows × 569 columns\n",
    "# Germany: 330955 rows × 569 columns\n",
    "# United kingdom: 260410 rows × 569 columns\n",
    "# France: 239035 rows × 569 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine datasets in 3 countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load single sales data ###\n",
    "# Mac\n",
    "df_uk_sales = pd.read_csv('/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/data/raw data/sales/2024_enhanced_uk.csv', encoding='unicode_escape',  engine='python', sep=None,  quoting=3, on_bad_lines='skip')\n",
    "df_fr_sales = pd.read_csv('/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/data/raw data/sales/2024_enhanced_fr.csv', encoding='unicode_escape',  engine='python', sep=None,  quoting=3, on_bad_lines='skip')\n",
    "df_ge_sales = pd.read_csv('/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/data/raw data/sales/2024_enhanced_ge.csv', encoding='unicode_escape',  engine='python')\n",
    "\n",
    "# rename the columns 'Country/Territory-Name' or 'ï»¿c' to 'country'\n",
    "df_uk_sales.rename(columns={'Country/Territory-Name':'country'}, inplace=True)\n",
    "df_fr_sales.rename(columns={'Country/Territory-Name':'country'}, inplace=True)\n",
    "df_ge_sales.rename(columns={'ï»¿c':'country'}, inplace=True)\n",
    "\n",
    "# concatenate the three dataframes horizontally\n",
    "df = pd.concat([df_uk_sales, df_fr_sales, df_ge_sales],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete rows with zero sales in year 2015-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with no sales in years 2015 to 2023\n",
    "df = df[(df.loc[:,'2015/01':'2023/12']!=0).any(axis=1)]\n",
    "\n",
    "# drop columns '1981/01' to '2014/12' and '2024/01' to '2024/06':\n",
    "df = df.drop(df.loc[:, '1981/01':'2014/12'].columns, axis = 1)\n",
    "df = df.drop(df.loc[:, '2024/01':'2024/06'].columns, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate monthly sales to annual sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate from monthly sales to annuals sales\n",
    "for year in range(2015, 2024):\n",
    "    month_columns = [f\"{year}/{month:02d}\" for month in range(1, 13)]  # this create a list of column names for the 12 months of the year, useful skill!\n",
    "    df[str(year)] = df[month_columns].sum(axis=1, skipna=True)         # Sum the monthly values for each year, handling missing columns\n",
    "df.drop(columns=df.filter(like='/'), inplace=True)                     # Drop the original monthly columns        # columns=df_s.filter(like='/') pick the columns that contain '/', useful skill!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save to a csv file\n",
    "df.to_csv('/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/data/processed data/sales/2015_2023_sales_all.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac\n",
    "df = pd.read_csv('/Users/simon/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Cars data/data/processed data/sales/2015_2023_sales_all.csv', low_memory=False)\n",
    "# Windows\n",
    "#df = pd.read_csv('C:/Users/uctpql0/OneDrive - University College London/Cars data/data/processed data/sales/2015_2023_sales_all.csv', encoding='unicode_escape',  engine='python', sep=None,  quoting=3, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1771550"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Show the number of sales in each year before aggregate duplicates\n",
    "#df['2019'].sum()   # 8,126,958\n",
    "#df['2020'].sum()   # 6,195,737\n",
    "#df['2021'].sum()   # 5,924,511\n",
    "#df['2022'].sum()   # 5,793,956\n",
    "#df['2023'].sum()   # 6,519,213\n",
    "\n",
    "# show the number of sales in 2023 for each country\n",
    "#df[df['country']== 'Germany']['2023'].sum()   # 2,844,609\n",
    "#df[df['country']== 'United Kingdom']['2023'].sum()   # 1,903,054\n",
    "#df[df['country']== 'France']['2023'].sum()   # 1,771,550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column types of df\n",
    "df.dtypes\n",
    "\n",
    "# remove the empty space at the beginning and the end of the string\n",
    "df['Price. (local)'] = df['Price. (local)'].str.strip() \n",
    "df['Price. (EUR)'] = df['Price. (EUR)'].str.strip()\n",
    "\n",
    "# for column 'Price. (local)', 'Price. (EUR), replace 'Unspecified' with NaN\n",
    "df['Price. (local)'] = df['Price. (local)'].replace('Unspecified', np.nan)\n",
    "df['Price. (EUR)'] = df['Price. (EUR)'].replace('Unspecified', np.nan)\n",
    "\n",
    "# change the column 'Price. (local)' to float\n",
    "df['Price. (local)'] = df['Price. (local)'].astype(float)\n",
    "df['Price. (EUR)'] = df['Price. (EUR)'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check for potential duplicates\n",
    "\n",
    "# create the list of column for grouping\n",
    "df_select = df.drop(df.loc[:, 'Price. (local)' : '2023'].columns, axis = 1)  \n",
    "df['duplicate'] = df_select.groupby(df_select.columns.tolist(), dropna=False).transform('size')     # option: grouped by selected columns: list(df_select.columns[1:])\n",
    "df_sort = df.sort_values(by = ['duplicate'] + df_select.columns.tolist(), ascending = [False] + [True]*(len(df_select.columns)))  # sort by 'duplicate_count' in descending order\n",
    "\n",
    "# observation: the same car model with different(updated) prices are treated as different observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the duplicates\n",
    "select_columns = df.columns[df.columns.get_loc('country'):df.columns.get_loc('Wheelbase')+1]    # good way to select columns\n",
    "df_agg = df.groupby(select_columns.tolist(), dropna=False).agg({'Price. (local)': 'mean', 'Price. (EUR)': 'mean', '2015':'sum', '2016':'sum', '2017':'sum', '2018':'sum', '2019':'sum', '2020':'sum', '2021':'sum', '2022':'sum', '2023':'sum'})\n",
    "df_agg = df_agg.reset_index() \n",
    "\n",
    "# aggregate the duplicates without grouping by 'country'\n",
    "select_columns = df.columns[df.columns.get_loc('Make Group'):df.columns.get_loc('Wheelbase')+1]\n",
    "df_agg = df.groupby(select_columns.tolist(), dropna=False).agg({'Price. (local)': 'mean', 'Price. (EUR)': 'mean', '2015':'sum', '2016':'sum', '2017':'sum', '2018':'sum', '2019':'sum', '2020':'sum', '2021':'sum', '2022':'sum', '2023':'sum'})\n",
    "df_agg = df_agg.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do-list: need to aggreagate body group into 5 classes: Car(Coupe, Sedan, Hatchback), SUV, Convertible, MPV, Wagon\n",
    "df['Body Group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Make Group'].nunique()   # 68 parent firms\n",
    "\n",
    "df['Make'].nunique()   # 120 brands\n",
    "\n",
    "df.groupby(['Make', 'Body Group', 'Fuel Type'], dropna=False).ngroups   # 1316 unique combinations of Brand, Body Group and Fuel Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
